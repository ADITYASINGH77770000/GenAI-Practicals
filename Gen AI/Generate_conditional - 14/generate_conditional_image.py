# -*- coding: utf-8 -*-
"""Generate Conditional Image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ikm_MNs63xjNAGSsmRzqx3kiCiL3iKHX
"""

import os

# Replace with your Hugging Face API token
os.environ["HUGGINGFACE_TOKEN"] = "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"

from diffusers import StableDiffusionPipeline
import torch

# Choose Stable Diffusion model
model_id = "runwayml/stable-diffusion-v1-5"

# Load pipeline with authentication
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    use_auth_token=os.environ["HUGGINGFACE_TOKEN"]
).to("cuda")

from PIL import Image
import matplotlib.pyplot as plt

def generate_image(prompt, steps=40, guidance=7.5):
    """
    Generate an image from a conditioned text prompt using Stable Diffusion.

    Args:
        prompt (str): Text description of the image.
        steps (int): Number of inference steps (higher = better quality, slower).
        guidance (float): How strongly the image should follow the text (higher = more literal).

    Returns:
        PIL.Image: Generated image
    """
    image = pipe(prompt, num_inference_steps=steps, guidance_scale=guidance).images[0]
    return image
# Conditioning prompts
prompts = [
    "A futuristic robot exploring Mars, cinematic digital art",
    "A watercolor painting of a mountain landscape with sunrise",
    "A photorealistic cat wearing a crown, 8k resolution",
]

images = [generate_image(p) for p in prompts]

# Display results
plt.figure(figsize=(15, 5))
for i, img in enumerate(images):
    plt.subplot(1, len(images), i+1)
    plt.imshow(img)
    plt.axis("off")
    plt.title(f"Prompt {i+1}")
plt.show()